拼写纠正项目
==========

整体思路：
-------
1. 预处理：分词、大小写转换、去标点
2. 建立词库，初始化cache，初始化索引
3. 开始查询。
    - 查词库，如果有说明输入正确，直接返回，并把该词occurance加1
    - 查cache
    - 从该词对应的索引中取出候选词，一一计算编辑距离
    - 找出编辑距离最短、出现频率最高的三个候选词，写入cache，返回。


网络库
-----
muduo


纠正程序
------
###预处理：
导入文本，中文分词。    实现：调用cppjieba

###建立词库、词频统计。   
实现：MAP(string, occurance)  O(logn)的查找速度   
中文标点的处理：预先建立所有中文标点的set，建立词库时，遍历每个中文字，在set中查找  

###纠正
方案：   
1. 对于目标词，计算出数个编辑距离最小的候选词
2. 当编辑距离相等时，比较候选词的出现频度，越常出现的越应该被推荐
实现：优先队列、编辑距离算法（动态规划、递归）


优化
---
###建立索引（倒排索引）   
目的：为了减少计算编辑距离的单词数目。因为索引中的单词至少有一个字母与目标词相同。   

**实现：**
1)对于仅有英文的情况，由于字母只有26个，可以直接根据ascii映射到26个list。
（list数组，下标是“字母－97”）。    
2)对于存在中文的情况，无论中英文，一律统一成`uint32_t`的单字。
由于中文的数量庞大，需要先用一个`MAP(uint32_t, list*)`索引list，
然后在各个list中存储含有该单字的词。

###LRU机制cache
实现：    
基于双向链表和哈希表。双向链表保证插入、更改操作o(1), 哈希保证查找o(1)。
要点：    
哈希用`unordered_map(key, node*)`，用key找到节点的指针，然后进行lru操作

###cachePool
目的：    
考虑服务器多线程的情况，单个cache的话，将出现多个线程抢锁等待的情况。如果给每个线程都分配一个cache，可能出现cache和threadpool类过于耦合的情况（Thread里面内置了Cache，查询时Thread调用TextQuery，然后TextQuery反过来调用Thread内部的Cache，缺点是模块之间做不到独立性。）   
  
方案：cachepool中有多个cache，由pool类管理。每次给用户分配一个cache使用，用完以后归还给pool。仅对cache的分配和归还操作加锁。   

优势：    
相比对整个cache查询／写入加锁，对cache分配加锁时间更短，所以提高了效率。   
可改进的方案：尝试给pool中每个cache独立的锁。   

剩余问题：   
存盘？多个cache之间的相互沟通？      
我的想法：如果4个，则各取前四分之一（因为LRU），放到一个buffer，再把buffer写入磁盘。然后把buffer的内容覆盖各个cache。

###其他优化
1. 如果编辑距离算出来很大，就直接抛弃，别进优先队列了
2. 如果单词长度差距过大就不计算编辑距离了，算出来也肯定很大，直接抛弃




